---
layout: post
title:  "Python 3.11 thirty percent faster indeed"
description: Personal observation of the performance gain in Python 3.11
---
<script src="/assets/js/plotly.js/1.58.4/plotly.min.js" integrity="sha512-odxyOOOwpEgYQnS+TzF/P33O+DfGNGqyh89pJ/u2addhMw9ZIef3M8aw/otYSgsPxLdZi3HQhlI9IiX3H5SxpA==" crossorigin="anonymous"></script>

**Two weeks back the new version 3.11 of Python was released with the promise of a significant speedup. 
Let's test it!**

For fun, I'm maintaining a [small benchmarking project](https://github.com/chr1st1ank/speeding-up-python).
There, a couple of computational tasks are solved with Python and with different speedup methods 
such as Cython, Numba and C extensions written in C++ or Rust. Main purpose for me was to figure 
out which method has the greatest effect and how good the user experience is.

Now that Python 3.11 is [officially released](https://www.python.org/downloads/release/python-3110/) 
with the note that a speedup of 10-60% was reached thanks to the [Faster CPython project](https://docs.python.org/3.11/whatsnew/3.11.html#faster-cpython),
it was time to check what it does to my benchmarks.

So I quickly updated my Python environment and rerun the benchmark suite. 
These are the results that I got:

<div id="chart-benchmark"  style="width:80%;"></div>
<script>
var py310 = {
  x: ["mergesort", "groupby_sum", "string_slice", "ngram_count", "ngram_count_parallel", "minhash"],
  y: [106, 86, 10, 459, 254, 566],
  name: 'Python 3.10',
  type: 'bar'
};
var py311 = {
  x: ["mergesort", "groupby_sum", "string_slice", "ngram_count", "ngram_count_parallel", "minhash"],
  y: [67, 71, 7, 421, 202, 498],
  text: ["-37 %","-17 %","-30 %","-8 %","-20 %","-12 %"],
  textposition: 'auto',
  name: 'Python 3.11',
  type: 'bar'
};
var data = [py310, py311];
var layout = {
  title: 'Benchmark runtime comparison Python 3.10/3.11',
  yaxis: {
    title: 'milliseconds (smaller is better)'
  },
  xaxis: {
    title: 'benchmark task',
    showgrid: false,
    zeroline: false,
    nticks: 6,
    barmode: 'group'
  },
  font: {
    family: 'Raleway, sans-serif'
  }
};
var options = {displayModeBar: false}
Plotly.newPlot(document.getElementById('chart-benchmark'), data, layout, options);
</script>

So, I can confirm some 8-37% speedup without changing a single line of code. This still doesn't 
make Python the new high performance language. But it is a lot, given that it comes for free with
the CPython interpreter.  Thanks to Guido, Mark and all the helping hands who are driving the
faster CPython project!

For reference below the complete results with Python 3.11. The 3.10 results and the code can be
found in the [Github repository](https://github.com/chr1st1ank/speeding-up-python/tree/7966d5208d313df9fe4e47ca4c5b50cb75702c28).

```
System information:

Architecture: x86_64 / 64bit
System: Linux / 5.15.11-arch2-1
Python: CPython 3.9.9 built with ('glibc', '2.33')
Processors: 
    16 x  AMD Ryzen 7 5700U with Radeon Graphics
    
mergesort
	  106ms - Python 3.10
	   67ms - Python 3.11
	  144ms - Numba
	   35ms - Cython
	    7ms - C++ (cython)
	    8ms - C++ (pybind11)
	    6ms - Rust
groupby_sum
	   86ms - Python 3.10
	   71ms - Python 3.11
	   69ms - Cython
	   58ms - Rust
string_slice
	   10ms - Python 3.10
	    7ms - Python 3.11
	    7ms - Cython
	   31ms - C++ (pybind11)
	   22ms - Rust
ngram_count
	  459ms - Python 3.10
	  421ms - Python 3.11
	  386ms - Numba
	  237ms - Cython
	  280ms - C++ (pybind11)
	  288ms - Rust
ngram_count_parallel
	  254ms - Python 3.10
	  202ms - Python 3.11
	  200ms - Rust
minhash
	  566ms - Python 3.10
	  498ms - Python 3.11
	  508ms - Cython
	  130ms - C++ (pybind11)
	  109ms - Rust
```
