{"cells":[{"source":["## Import dependencies"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["from pathlib import Path\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split"]},{"source":["## Initial look at the data"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                    Text   Language\n","10220  ನಾವು ಚಲನಚಿತ್ರಗಳಿಗೆ ಹೋಗುತ್ತೇವೆ ಎಂದು ನೀವು ಏನು ಹೇ...    Kannada\n","9794                 Sie treffen den Nagel auf den Kopf.     German\n","7355   L'apprendimento automatico si sviluppa con lo ...    Italian\n","1404   ഇന്ന് ഇന്റർനെറ്റിൽ ഏറ്റവും പ്രശസ്തമായ പൊതു-അവല...  Malayalam\n","6418   еще один способ спросить, не уловил ли вы част...    Russian"],"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Language</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10220</th>\n      <td>ನಾವು ಚಲನಚಿತ್ರಗಳಿಗೆ ಹೋಗುತ್ತೇವೆ ಎಂದು ನೀವು ಏನು ಹೇ...</td>\n      <td>Kannada</td>\n    </tr>\n    <tr>\n      <th>9794</th>\n      <td>Sie treffen den Nagel auf den Kopf.</td>\n      <td>German</td>\n    </tr>\n    <tr>\n      <th>7355</th>\n      <td>L'apprendimento automatico si sviluppa con lo ...</td>\n      <td>Italian</td>\n    </tr>\n    <tr>\n      <th>1404</th>\n      <td>ഇന്ന് ഇന്റർനെറ്റിൽ ഏറ്റവും പ്രശസ്തമായ പൊതു-അവല...</td>\n      <td>Malayalam</td>\n    </tr>\n    <tr>\n      <th>6418</th>\n      <td>еще один способ спросить, не уловил ли вы част...</td>\n      <td>Russian</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":2}],"source":["data = pd.read_csv(Path(globals()['_dh'][0]) / \"data\" / \"LanguageDetection.csv\", sep=\",\")\n","data.sample(5)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of samples by language:\n"]},{"output_type":"execute_result","data":{"text/plain":["Language\n","Hindi           63\n","Greek          365\n","Kannada        369\n","Danish         428\n","Tamil          469\n","German         470\n","Turkish        474\n","Arabic         536\n","Dutch          546\n","Malayalam      594\n","Sweedish       676\n","Russian        692\n","Italian        698\n","Portugeese     739\n","Spanish        819\n","French        1014\n","English       1385\n","Name: Text, dtype: int64"]},"metadata":{},"execution_count":3}],"source":["print(\"Number of samples by language:\")\n","data.groupby(by=[\"Language\"]).count()[\"Text\"].sort_values()"]},{"source":["## Train/test split"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["x = data[\"Text\"].values\n","y = data[\"Language\"].values\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["(8269,)\n"]},{"output_type":"execute_result","data":{"text/plain":["array(['τώρα αργότερα η Μέλι και ο Τέρι έσπασαν αντίο στον παλιό τους φίλο και πήγαν να χαμογελούν ο ένας στον άλλο κρυφά εκείνο το βράδυ, τόσο μητέρα όσο και κόρη.',\n","       'Améliorez-le ou discutez-en.',\n","       'non ne vale la pena, personalmente amo la frase you rock che significa che sei fantastico.',\n","       ...,\n","       'Si alguien te pregunta si estás cansado y quieres decir que no estás cansado en absoluto.',\n","       'Due to its generality, the field is studied in many other disciplines, such as game theory, control theory, operations research, information theory, simulation-based optimization, multi-agent systems, swarm intelligence, statistics and genetic algorithms.',\n","       'Sono disponibili inoltre applicazioni dedicate per i vari dispositivi mobili, ad esempio Wikipedia Mobile per iPhone e Wikipedia Mobile per Android.'],\n","      dtype=object)"]},"metadata":{},"execution_count":5}],"source":["print(x_train.shape)\n","x_train"]},{"source":["## ML pipeline"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Pipeline(steps=[('tfidf',\n","                 TfidfVectorizer(lowercase=False, token_pattern='[\\\\w_]{2,}')),\n","                ('naive_bayes', MultinomialNB(alpha=0.01))])"]},"metadata":{},"execution_count":6}],"source":["from sklearn.pipeline import Pipeline\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn import metrics\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","\n","\n","\n","clf_pipeline = Pipeline([\n","    (\"tfidf\", TfidfVectorizer(token_pattern=r\"[\\w_]{2,}\", lowercase=False)),\n","    (\"naive_bayes\", MultinomialNB(alpha=.01)),\n","])\n","#clf_pipeline = Pipeline([\n","#    (\"wordcount\", CountVectorizer()),\n","#    (\"naive_bayes\", MultinomialNB(alpha=.01)),\n","#])\n","clf_pipeline.fit(x_train, y_train)\n"]},{"source":["## Test prediction and sanity check"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n\n      Arabic       1.00      0.98      0.99       106\n      Danish       0.99      0.96      0.97        73\n       Dutch       0.99      0.98      0.99       111\n     English       0.92      1.00      0.96       291\n      French       1.00      0.99      0.99       219\n      German       1.00      0.98      0.99        93\n       Greek       1.00      1.00      1.00        68\n       Hindi       1.00      1.00      1.00        10\n     Italian       1.00      0.99      0.99       145\n     Kannada       1.00      1.00      1.00        66\n   Malayalam       1.00      0.98      0.99       121\n  Portugeese       0.99      0.97      0.98       144\n     Russian       1.00      0.99      0.99       136\n     Spanish       0.99      0.97      0.98       160\n    Sweedish       0.99      0.98      0.99       133\n       Tamil       1.00      0.99      0.99        87\n     Turkish       1.00      0.98      0.99       105\n\n    accuracy                           0.98      2068\n   macro avg       0.99      0.98      0.99      2068\nweighted avg       0.99      0.98      0.98      2068\n\n"]}],"source":["pred = clf_pipeline.predict(x_test)\n","\n","print(metrics.classification_report(y_test, pred))"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Ein kleiner deutscher Text => German 0.768441150069108\nA small text without meaning => English 0.9986415618842468\nC'è un pò d'italiano => Italian 0.7141641875031932\nUne petite histoire de Paris => French 0.9968009803867346\nГенсек ООН призвал к соблюдению перемирия во время Олимпиады => Russian 0.9912020536752277\n"]}],"source":["for sample in [\"Ein kleiner deutscher Text\", \"A small text without meaning\", \"C'è un pò d'italiano\", \"Une petite histoire de Paris\", \"Генсек ООН призвал к соблюдению перемирия во время Олимпиады\"]:\n","    print(sample, \"=>\", clf_pipeline.predict(np.array([sample]))[0], np.max(clf_pipeline.predict_proba(np.array([sample]))[0]))\n","    clf_pipeline.predict_proba(np.array([sample]))[0]\n","    print(sample, \"=>\", clf_pipeline.predict(np.array([sample]))[0], np.max()"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{},"execution_count":38}],"source":["np.argmax(clf_pipeline.predict_proba(np.array([\"A small text without meaning\"])))"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'English'"]},"metadata":{},"execution_count":39}],"source":["clf_pipeline.classes_[3]"]},{"source":["## Serialize model"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["import pickle\n","\n","with open(\"data/classifier.pickle\", \"wb\") as f:\n","    pickle.dump(clf_pipeline, f)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"output_type":"stream","name":"stderr","text":["/home/christian/.cache/pypoetry/virtualenvs/demo-api-td6ufWwZ-py3.9/lib/python3.9/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute coef_ was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n","  warnings.warn(msg, category=FutureWarning)\n","/home/christian/.cache/pypoetry/virtualenvs/demo-api-td6ufWwZ-py3.9/lib/python3.9/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute intercept_ was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n","  warnings.warn(msg, category=FutureWarning)\n","/home/christian/.cache/pypoetry/virtualenvs/demo-api-td6ufWwZ-py3.9/lib/python3.9/site-packages/skl2onnx/common/_container.py:603: UserWarning: Unable to find operator 'Tokenizer' in domain 'com.microsoft' in ONNX, op_version is forced to 1.\n","  warnings.warn(\n"]}],"source":["import skl2onnx\n","from skl2onnx import convert_sklearn\n","from skl2onnx.common.data_types import StringTensorType\n","\n","tfidf_settings = {\n","    TfidfVectorizer: {\n","        \"tokenexp\": r\"[\\pL\\pN_]{2,}\"\n","    }\n","}\n","initial_type = [('string_input', StringTensorType([None, 1]))]\n","onx = convert_sklearn(clf_pipeline, initial_types=initial_type, options=tfidf_settings)\n","with open(\"data/classifier.onnx\", \"wb\") as f:\n","    f.write(onx.SerializeToString())"]},{"source":["## Differences in tokenization and normalization:"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["TfidfVectorizer(lowercase=False, token_pattern='[İ\\\\w_]{2,}')"]},"metadata":{},"execution_count":11}],"source":["vectorizer = TfidfVectorizer(token_pattern=r\"[İ\\w_]{2,}\", lowercase=False)\n","vectorizer.fit(x_train)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["tfidf_settings = {\n","    TfidfVectorizer: {\n","        \"tokenexp\": r\"[\\pL\\pN_]{2,}\"\n","    }\n","}\n","initial_type = [('string_input', StringTensorType([None, 1]))]\n","onx = convert_sklearn(vectorizer, initial_types=initial_type, options=tfidf_settings)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["import onnxruntime\n","\n","with open(\"data/vectorizer.onnx\", \"wb\") as f:\n","    f.write(onx.SerializeToString())\n","session = onnxruntime.InferenceSession(\"data/vectorizer.onnx\")\n","inputs = {'string_input': x_test[:1]}\n","pred_onx = session.run(None, {\"string_input\": np.array([\"И с этими словами она села в его карету, и, даже не\"]).reshape(1, 1)})"]},{"cell_type":"code","execution_count":15,"metadata":{"tags":[]},"outputs":[],"source":["for t in x_train:\n","    pred_sklearn = np.sum(vectorizer.transform(np.array([t])))\n","    pred_onx = np.sum(session.run(None, {\"string_input\": np.array([t]).reshape(1, 1)}))\n","    if abs(pred_onx - pred_sklearn) > 0.01:\n","        print(t, pred_sklearn, pred_onx)\n","        print(sorted(list(vectorizer.inverse_transform(vectorizer.transform(np.array([t])))[0])))\n","        print(sorted(list(vectorizer.inverse_transform(session.run(None, {\"string_input\": np.array([t]).reshape(1, 1)})[0])[0])))"]},{"source":["## Test prediction with ONNX model"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["predict ['Russian']\npredict_proba [{'Arabic': 7.943455784698017e-06, 'Danish': 1.0405490684206598e-05, 'Dutch': 8.303594768221956e-06, 'English': 2.679041699593654e-06, 'French': 3.670612613859703e-06, 'German': 1.1265211469435599e-05, 'Greek': 1.0832965926965699e-05, 'Hindi': 1.1893760529346764e-05, 'Italian': 5.484678695211187e-06, 'Kannada': 1.8420292690279894e-05, 'Malayalam': 1.082171183952596e-05, 'Portugeese': 5.10070185555378e-06, 'Russian': 0.9998569488525391, 'Spanish': 5.064754532213556e-06, 'Sweedish': 6.081358151277527e-06, 'Tamil': 1.3298573321662843e-05, 'Turkish': 1.1620059012784623e-05}]\n"]}],"source":["import onnxruntime\n","\n","session = onnxruntime.InferenceSession(\"data/classifier.onnx\")\n","pred_onx = session.run(None, {\"string_input\": np.array([\"И с этими словами она села в его карету, и, даже не\"]).reshape(1, 1)})\n","print(\"predict\", pred_onx[0])\n","print(\"predict_proba\", pred_onx[1])"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Ein kleiner deutscher Text => ['German'] 0.7684409618377686\nA small text without meaning => ['English'] 0.9986410140991211\nC'è un pò d'italiano => ['Italian'] 0.7141642570495605\nUne petite histoire de Paris => ['French'] 0.9968007802963257\nГенсек ООН призвал к соблюдению перемирия во время Олимпиады => ['Russian'] 0.991202175617218\n"]}],"source":["for sample in [\"Ein kleiner deutscher Text\", \"A small text without meaning\", \"C'è un pò d'italiano\", \"Une petite histoire de Paris\", \"Генсек ООН призвал к соблюдению перемирия во время Олимпиады\"]:\n","    pred_onx = session.run(None, {\"string_input\": np.array([sample]).reshape(1, 1)})\n","    print(sample, \"=>\", pred_onx[0], pred_onx[1][0][pred_onx[0][0]])\n","    #print(\"predict_proba\", pred_onx[1])"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7684409618377686"]},"metadata":{},"execution_count":33}],"source":["\n"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n\n      Arabic       1.00      0.98      0.99       106\n      Danish       0.99      0.96      0.97        73\n       Dutch       0.99      0.98      0.99       111\n     English       0.92      1.00      0.96       291\n      French       1.00      0.99      0.99       219\n      German       1.00      0.98      0.99        93\n       Greek       1.00      1.00      1.00        68\n       Hindi       1.00      1.00      1.00        10\n     Italian       1.00      0.99      0.99       145\n     Kannada       1.00      1.00      1.00        66\n   Malayalam       1.00      0.98      0.99       121\n  Portugeese       0.99      0.97      0.98       144\n     Russian       1.00      0.99      0.99       136\n     Spanish       0.99      0.97      0.98       160\n    Sweedish       0.99      0.98      0.99       133\n       Tamil       1.00      0.99      0.99        87\n     Turkish       1.00      0.98      0.99       105\n\n    accuracy                           0.98      2068\n   macro avg       0.99      0.98      0.99      2068\nweighted avg       0.99      0.98      0.98      2068\n\n"]}],"source":["pred_onnx = session.run(None, {\"string_input\": np.array([s.encode(\"utf-8\") for s in x_test]).reshape(len(x_test), 1)})\n","print(metrics.classification_report(y_test, pred_onnx[0]))\n"]},{"source":["## Benchmarking"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["def sample():\n","    sample_size = 1\n","    for i in range(0, len(x_test)-sample_size, sample_size):\n","        yield x_test[i:i+sample_size]\n","\n","def benchmark_onnx():\n","    for t in sample():\n","        pred_onx = session.run(None, {\"string_input\": np.array([t]).reshape(len(t), 1)})\n","\n","def benchmark_sklearn():\n","    for t in sample():\n","        pred = clf_pipeline.predict(np.array(t))"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 9.46 s, sys: 113 ms, total: 9.57 s\nWall time: 9.67 s\n"]}],"source":["%time benchmark_sklearn()"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 6.07 s, sys: 53.9 ms, total: 6.13 s\nWall time: 3.1 s\n"]}],"source":["%time benchmark_onnx()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"orig_nbformat":4,"kernelspec":{"name":"python3","display_name":"Python 3.9.6 64-bit ('demo-api-td6ufWwZ-py3.9': venv)"},"interpreter":{"hash":"0d06497f08ec5d0d372847304a386590630b6df8b8a02230ab933dab27f7787f"}}}