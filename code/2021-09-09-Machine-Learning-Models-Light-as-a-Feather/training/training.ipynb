{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_folder = Path(globals()['_dh'][0]) / \"..\" / \"data\"\n",
    "output_folder = Path(globals()['_dh'][0]) / \"output\"\n",
    "output_folder.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial look at the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a labeled list of short text fragments in 17 different languages. These are some examples of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4732</th>\n",
       "      <td>graag gedaan.</td>\n",
       "      <td>Dutch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6174</th>\n",
       "      <td>Запросы, которые не могут быть обслужены кэшем...</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>[48] Over nine-tenths of the total biomass on ...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7096</th>\n",
       "      <td>af et stort og storslået gyldent slot narcisa ...</td>\n",
       "      <td>Danish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10320</th>\n",
       "      <td>ನೀನು ತಿನ್ನು.</td>\n",
       "      <td>Kannada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text Language\n",
       "4732                                       graag gedaan.    Dutch\n",
       "6174   Запросы, которые не могут быть обслужены кэшем...  Russian\n",
       "153    [48] Over nine-tenths of the total biomass on ...  English\n",
       "7096   af et stort og storslået gyldent slot narcisa ...   Danish\n",
       "10320                                      ನೀನು ತಿನ್ನು.  Kannada"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(data_folder / \"LanguageDetection.csv\", sep=\",\")\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution is of languages is relatively equal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples by language:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Language</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hindi</th>\n",
       "      <td>63</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Greek</th>\n",
       "      <td>365</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kannada</th>\n",
       "      <td>369</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Danish</th>\n",
       "      <td>428</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tamil</th>\n",
       "      <td>469</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>German</th>\n",
       "      <td>470</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Turkish</th>\n",
       "      <td>474</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arabic</th>\n",
       "      <td>536</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dutch</th>\n",
       "      <td>546</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Malayalam</th>\n",
       "      <td>594</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sweedish</th>\n",
       "      <td>676</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Russian</th>\n",
       "      <td>692</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Italian</th>\n",
       "      <td>698</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Portugeese</th>\n",
       "      <td>739</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spanish</th>\n",
       "      <td>819</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>French</th>\n",
       "      <td>1014</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>English</th>\n",
       "      <td>1385</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            count  percent\n",
       "Language                  \n",
       "Hindi          63      0.6\n",
       "Greek         365      3.5\n",
       "Kannada       369      3.6\n",
       "Danish        428      4.1\n",
       "Tamil         469      4.5\n",
       "German        470      4.5\n",
       "Turkish       474      4.6\n",
       "Arabic        536      5.2\n",
       "Dutch         546      5.3\n",
       "Malayalam     594      5.7\n",
       "Sweedish      676      6.5\n",
       "Russian       692      6.7\n",
       "Italian       698      6.8\n",
       "Portugeese    739      7.1\n",
       "Spanish       819      7.9\n",
       "French       1014      9.8\n",
       "English      1385     13.4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = data.groupby(by=[\"Language\"]).count()[\"Text\"].sort_values()\n",
    "\n",
    "print(\"Number of samples by language:\")\n",
    "pd.DataFrame({\"count\": samples, \"percent\": (samples/sum(samples)).round(3)*100})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start our machine learning task by splitting the data into a train and a test set, so that we can later measure the performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[\"Text\"].values\n",
    "y = data[\"Language\"].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to create a scikit-learn pipeline for the preprocessing and training. The two steps in the pipeline are the Tf-idf vectorizer and a Naive Bayes model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(lowercase=False, token_pattern='[\\\\w_]{2,}')),\n",
       "                ('naive_bayes', MultinomialNB(alpha=0.01))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "\n",
    "clf_pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(token_pattern=r\"[\\w_]{2,}\", lowercase=False)),\n",
    "    (\"naive_bayes\", MultinomialNB(alpha=.01)),\n",
    "])\n",
    "# clf_pipeline = Pipeline([\n",
    "#    (\"wordcount\", CountVectorizer()),\n",
    "#    (\"naive_bayes\", MultinomialNB(alpha=.01)),\n",
    "# ])\n",
    "clf_pipeline.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test prediction and sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       1.00      0.98      0.99       106\n",
      "      Danish       0.99      0.96      0.97        73\n",
      "       Dutch       0.99      0.98      0.99       111\n",
      "     English       0.92      1.00      0.96       291\n",
      "      French       1.00      0.99      0.99       219\n",
      "      German       1.00      0.98      0.99        93\n",
      "       Greek       1.00      1.00      1.00        68\n",
      "       Hindi       1.00      1.00      1.00        10\n",
      "     Italian       1.00      0.99      0.99       145\n",
      "     Kannada       1.00      1.00      1.00        66\n",
      "   Malayalam       1.00      0.98      0.99       121\n",
      "  Portugeese       0.99      0.97      0.98       144\n",
      "     Russian       1.00      0.99      0.99       136\n",
      "     Spanish       0.99      0.97      0.98       160\n",
      "    Sweedish       0.99      0.98      0.99       133\n",
      "       Tamil       1.00      0.99      0.99        87\n",
      "     Turkish       1.00      0.98      0.99       105\n",
      "\n",
      "    accuracy                           0.98      2068\n",
      "   macro avg       0.99      0.98      0.99      2068\n",
      "weighted avg       0.99      0.98      0.98      2068\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = clf_pipeline.predict(x_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ein kleiner deutscher Text => German 0.768441150069108\n",
      "A small text without meaning => English 0.9986415618842468\n",
      "C'è un pò d'italiano => Italian 0.7141641875031932\n",
      "Une petite histoire de Paris => French 0.9968009803867346\n",
      "Генсек ООН призвал к соблюдению перемирия во время Олимпиады => Russian 0.9912020536752277\n"
     ]
    }
   ],
   "source": [
    "for sample in [\"Ein kleiner deutscher Text\", \"A small text without meaning\", \"C'è un pò d'italiano\", \"Une petite histoire de Paris\", \"Генсек ООН призвал к соблюдению перемирия во время Олимпиады\"]:\n",
    "    print(sample, \"=>\", clf_pipeline.predict(np.array([sample]))[0], np.max(clf_pipeline.predict_proba(np.array([sample]))[0]))\n",
    "    clf_pipeline.predict_proba(np.array([sample]))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serialize model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Pickle the sklearn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (output_folder / \"classifier.pickle\").open(\"wb\") as f:\n",
    "    pickle.dump(clf_pipeline, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Convert to and store Onnx model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christian/.cache/pypoetry/virtualenvs/language-classification-training-3IcJ1YFX-py3.9/lib/python3.9/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute coef_ was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/christian/.cache/pypoetry/virtualenvs/language-classification-training-3IcJ1YFX-py3.9/lib/python3.9/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute intercept_ was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/christian/.cache/pypoetry/virtualenvs/language-classification-training-3IcJ1YFX-py3.9/lib/python3.9/site-packages/skl2onnx/common/_container.py:607: UserWarning: Unable to find operator 'Tokenizer' in domain 'com.microsoft' in ONNX, op_version is forced to 1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import StringTensorType\n",
    "\n",
    "# For tf-idf additional settings are necessary\n",
    "model_settings = {\n",
    "    TfidfVectorizer: {\n",
    "    # CountVectorizer: {\n",
    "        \"tokenexp\": r\"[\\pL\\pN_]{2,}\"\n",
    "    }\n",
    "}\n",
    "# The input of ONNX models is strongly typed. So we need to define that the input is a string\n",
    "initial_type = [('string_input', StringTensorType([None, 1]))]\n",
    "# Actual conversion\n",
    "onx = convert_sklearn(clf_pipeline, initial_types=initial_type, options=model_settings)\n",
    "\n",
    "# Serialize and store the model\n",
    "with (output_folder / \"classifier.onnx\").open(\"wb\") as f:\n",
    "    f.write(onx.SerializeToString())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test prediction with ONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict ['Russian']\n",
      "predict_proba [{'Arabic': 7.943455784698017e-06, 'Danish': 1.0405490684206598e-05, 'Dutch': 8.303594768221956e-06, 'English': 2.679041699593654e-06, 'French': 3.670612613859703e-06, 'German': 1.1265211469435599e-05, 'Greek': 1.0832965926965699e-05, 'Hindi': 1.1893760529346764e-05, 'Italian': 5.484678695211187e-06, 'Kannada': 1.8420292690279894e-05, 'Malayalam': 1.082171183952596e-05, 'Portugeese': 5.10070185555378e-06, 'Russian': 0.9998569488525391, 'Spanish': 5.064754532213556e-06, 'Sweedish': 6.081358151277527e-06, 'Tamil': 1.3298573321662843e-05, 'Turkish': 1.1620059012784623e-05}]\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime\n",
    "\n",
    "session = onnxruntime.InferenceSession(str(output_folder / \"classifier.onnx\"))\n",
    "pred_onx = session.run(None, {\"string_input\": np.array([\"И с этими словами она села в его карету, и, даже не\"]).reshape(1, 1)})\n",
    "print(\"predict\", pred_onx[0])\n",
    "print(\"predict_proba\", pred_onx[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ein kleiner deutscher Text => ['German'] 0.7684409618377686\n",
      "A small text without meaning => ['English'] 0.9986410140991211\n",
      "C'è un pò d'italiano => ['Italian'] 0.7141642570495605\n",
      "Une petite histoire de Paris => ['French'] 0.9968007802963257\n",
      "Генсек ООН призвал к соблюдению перемирия во время Олимпиады => ['Russian'] 0.991202175617218\n"
     ]
    }
   ],
   "source": [
    "for sample in [\"Ein kleiner deutscher Text\", \"A small text without meaning\", \"C'è un pò d'italiano\", \"Une petite histoire de Paris\", \"Генсек ООН призвал к соблюдению перемирия во время Олимпиады\"]:\n",
    "    pred_onx = session.run(None, {\"string_input\": np.array([sample]).reshape(1, 1)})\n",
    "    print(sample, \"=>\", pred_onx[0], pred_onx[1][0][pred_onx[0][0]])\n",
    "    #print(\"predict_proba\", pred_onx[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       1.00      0.98      0.99       106\n",
      "      Danish       0.99      0.96      0.97        73\n",
      "       Dutch       0.99      0.98      0.99       111\n",
      "     English       0.92      1.00      0.96       291\n",
      "      French       1.00      0.99      0.99       219\n",
      "      German       1.00      0.98      0.99        93\n",
      "       Greek       1.00      1.00      1.00        68\n",
      "       Hindi       1.00      1.00      1.00        10\n",
      "     Italian       1.00      0.99      0.99       145\n",
      "     Kannada       1.00      1.00      1.00        66\n",
      "   Malayalam       1.00      0.98      0.99       121\n",
      "  Portugeese       0.99      0.97      0.98       144\n",
      "     Russian       1.00      0.99      0.99       136\n",
      "     Spanish       0.99      0.97      0.98       160\n",
      "    Sweedish       0.99      0.98      0.99       133\n",
      "       Tamil       1.00      0.99      0.99        87\n",
      "     Turkish       1.00      0.98      0.99       105\n",
      "\n",
      "    accuracy                           0.98      2068\n",
      "   macro avg       0.99      0.98      0.99      2068\n",
      "weighted avg       0.99      0.98      0.98      2068\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_onnx = session.run(None, {\"string_input\": np.array([s.encode(\"utf-8\") for s in x_test]).reshape(len(x_test), 1)})\n",
    "print(metrics.classification_report(y_test, pred_onnx[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing file sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2M\t./output/classifier.onnx\r\n",
      "11M\t./output/classifier.pickle\r\n"
     ]
    }
   ],
   "source": [
    "!du -ha ./output/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['English']\n",
      "Current memory usage is 0.010034MB; Peak with sklearn was 20.2247MB\n"
     ]
    }
   ],
   "source": [
    "import tracemalloc\n",
    "\n",
    "tracemalloc.start()\n",
    "with (output_folder / \"classifier.pickle\").open(\"rb\") as f:\n",
    "    m = pickle.load(f)\n",
    "pred = m.predict(np.array([\"what language is it?\"]))\n",
    "print(pred)\n",
    "del pred, m\n",
    "current, peak = tracemalloc.get_traced_memory()\n",
    "print(f\"Current memory usage is {current / 10**6}MB; Peak with sklearn was {peak / 10**6}MB\")\n",
    "tracemalloc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['English']\n",
      "Current memory usage is 0.005823MB; Peak with onnx was 0.01701MB\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime\n",
    "\n",
    "tracemalloc.start()\n",
    "session = onnxruntime.InferenceSession(str(output_folder / \"classifier.onnx\"))\n",
    "pred_onx, *_ = session.run(None, {\"string_input\": np.array([\"what language is it?\"]).reshape(1, 1)})\n",
    "print(pred_onx)\n",
    "del session, pred_onx\n",
    "current, peak = tracemalloc.get_traced_memory()\n",
    "print(f\"Current memory usage is {current / 10**6}MB; Peak with onnx was {peak / 10**6}MB\")\n",
    "tracemalloc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing prediction speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (output_folder / \"classifier.pickle\").open(\"rb\") as f:\n",
    "    clf_pipeline = pickle.load(f)\n",
    "\n",
    "sess_options = onnxruntime.SessionOptions()\n",
    "sess_options.intra_op_num_threads = 1\n",
    "# sess_options.execution_mode = onnxruntime.ExecutionMode.ORT_PARALLEL\n",
    "sess_options.execution_mode = onnxruntime.ExecutionMode.ORT_SEQUENTIAL\n",
    "sess_options.graph_optimization_level = onnxruntime.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "session = onnxruntime.InferenceSession(str(output_folder / \"classifier.onnx\"), sess_options=sess_options)\n",
    "\n",
    "def sample():\n",
    "    batch_size = 1\n",
    "    for i in range(0, 1000, batch_size):\n",
    "    # for i in range(0, len(x_test)-batch_size, batch_size):\n",
    "        yield x_test[i:i+batch_size]\n",
    "\n",
    "def benchmark_onnx():\n",
    "    for t in sample():\n",
    "        pred_onx, *_ = session.run(None, {\"string_input\": np.array([t]).reshape(len(t), 1)})\n",
    "\n",
    "def benchmark_sklearn():\n",
    "    for t in sample():\n",
    "        pred = clf_pipeline.predict(np.array(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.11 s ± 309 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit benchmark_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.54 s ± 93.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit benchmark_onnx()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b1369df39e3417fc6e0cf6e36dee8309bdee89bc4efd538bf35008d7b2e1e9fc"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
